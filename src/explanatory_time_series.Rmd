---
title: "Untitled"
author: Acer
date: 07/01/2020
output: rmarkdown::html_vignette
---
```{r}

rm(list = ls())
#Choisir l'emplacement des données
path = file.choose()
source(path)


library(KFAS)
ggplot(daily_data,  aes(x=Date, y=PT08.S4.NO2.)) + geom_line()

```
```{r}
#On stationnarise la série
ts_PT08.S4.NO2. = ts(daily_data$PT08.S4.NO2., start=1, frequency =1)
ts_stat_PT08.S4.NO2. = diff(ts_PT08.S4.NO2.)
daily_data$PT08.S4.NO2._stat <- c(0,diff(daily_data$PT08.S4.NO2.))
ggplot(data=daily_data, aes(x=Date, y=PT08.S4.NO2._stat)) + geom_line()


```


```{r}
#On teste la stationnarité en utilisant le test de Dicky-Fuller : H0 correspond à l'hypothèse de non stationnarité : présence d'une racine unitaire dans l'équation canonique de la série, ici la p-value est 0.01 donc on rejette H0 , la série est bien stationnaire
library(tseries)
test_stationnarity = adf.test(ts_stat_PT08.S4.NO2.)
print(test_stationnarity)
```

```{r}
ggplot(daily_data,  aes(x=Date, y=PT08.S1.CO.)) + geom_line()
```

```{r}
#On stationnarise la série
ts_PT08.S1.CO. = ts(daily_data$PT08.S1.CO., start=1, frequency =1)
ts_stat_PT08.S1.CO. = diff(ts_PT08.S1.CO.)
daily_data$PT08.S1.CO._stat <- c(0,diff(daily_data$PT08.S1.CO.))
ggplot(data=daily_data, aes(x=Date, y=PT08.S1.CO._stat)) + geom_line()
```


```{r}
#On teste la stationnarité en utilisant le test de Dicky-Fuller : H0 correspond à l'hypothèse de non stationnarité : présence d'une racine unitaire dans l'équation canonique de la série, ici la p-value est 0.01 donc on rejette H0 , la série est bien stationnaire
library(tseries)
test_stationnarity = adf.test(ts_stat_PT08.S1.CO.)
print(test_stationnarity)
```
```{r}
#On stationnarise la série
ts_PT08.S2.NMHC. = ts(daily_data$PT08.S2.NMHC., start=1, frequency =1)
ts_stat_PT08.S2.NMHC. = diff(ts_PT08.S2.NMHC.)
daily_data$PT08.S2.NMHC._stat <- c(0,diff(daily_data$PT08.S2.NMHC.))
ggplot(data=daily_data, aes(x=Date, y=PT08.S4.NO2._stat)) + geom_line()

```
```{r}
#On teste la stationnarité en utilisant le test de Dicky-Fuller : H0 correspond à l'hypothèse de non stationnarité : présence d'une racine unitaire dans l'équation canonique de la série, ici la p-value est 0.01 donc on rejette H0 , la série est bien stationnaire
library(tseries)
test_stationnarity = adf.test(ts_stat_PT08.S2.NMHC.)
print(test_stationnarity)
```
```{r}
#On stationnarise la série
ts_PT08.S5.O3. = ts(daily_data$PT08.S5.O3., start=1, frequency =1)
ts_stat_PT08.S5.O3. = diff(ts_PT08.S5.O3.)
daily_data$PT08.S5.O3._stat <- c(0,diff(daily_data$PT08.S5.O3.))
ggplot(data=daily_data, aes(x=Date, y=PT08.S5.O3._stat)) + geom_line()
```
```{r}
#On teste la stationnarité en utilisant le test de Dicky-Fuller : H0 correspond à l'hypothèse de non stationnarité : présence d'une racine unitaire dans l'équation canonique de la série, ici la p-value est 0.01 donc on rejette H0 , la série est bien stationnaire
library(tseries)
test_stationnarity = adf.test(ts_stat_PT08.S5.O3.)
print(test_stationnarity)
```
```{r}
#now that we have stationarized, we can create the model
ts_PTO8.S3.NOx. = ts(daily_data$PT08.S3.NOx., start=1, frequency = 1)
ts_stat_PTO8.S3.NOx. = diff(ts_PTO8.S3.NOx.)
n<-length(ts_stat_PTO8.S3.NOx.)
y<-ts(ts_stat_PTO8.S3.NOx. ,frequency = 4, start = c(1959,2))
ytraining<-ts(y[-((n-5):n)],frequency = 4, start = c(1959,2))

#FIRST <- diff(daily_data$PT08.S5.O3.)
#SECOND <- diff(daily_data$PT08.S1.CO.)
#THIRD <- diff(daily_data$PT08.S2.NMHC.)
#FOURTH <- diff(daily_data$PT08.S4.NO2.)
ts_PT08.S5.O3. = ts(daily_data$PT08.S5.O3., start=1, frequency = 1)
ts_stat_PT08.S5.O3. = diff(ts_PT08.S5.O3.)
FIRST = ts_stat_PT08.S5.O3.[(length(ts_stat_PT08.S5.O3.)-4 ):length(ts_stat_PT08.S5.O3.)]

ts_PT08.S1.CO. = ts(daily_data$PT08.S1.CO., start=1, frequency = 1)
ts_stat_PT08.S1.CO. = diff(ts_PT08.S1.CO.)
SECOND = ts_stat_PT08.S1.CO.[(length(ts_stat_PT08.S1.CO.)-4 ):length(ts_stat_PT08.S1.CO.)]

ts_PT08.S2.NMHC. = ts(daily_data$PT08.S2.NMHC., start=1, frequency = 1)
ts_stat_PT08.S2.NMHC. = diff(ts_PT08.S2.NMHC.)
THIRD = ts_stat_PT08.S2.NMHC.[(length(ts_stat_PT08.S2.NMHC.)-4 ):length(ts_stat_PT08.S2.NMHC.)]

ts_PT08.S4.NO2. = ts(daily_data$PT08.S4.NO2., start=1, frequency = 1)
ts_stat_PT08.S4.NO2. = diff(ts_PT08.S4.NO2.)
FOURTH = ts_stat_PT08.S4.NO2.[(length(ts_stat_PT08.S4.NO2.)-4 ):length(ts_stat_PT08.S4.NO2.)]

Y<-ts(cbind(ytraining,lag(ytraining,1),lag(ytraining,2),lag(ytraining,3),lag(ytraining,4),lag(ytraining,5),lag(ytraining,6),lag(ytraining,7),lag(ytraining,8),lag(ytraining,9),lag(ytraining,10)))
Y <- Y[-c(1:5),]
tail(Y)   # NA for the lagged versions at the end because we do not know the future!

```
```{r}
print(class(data))
H <- diag(1,5)
H = as.data.frame(H)
#model <- SSModel(Y[-1,] ~-1+ SSMregression(~ FIRST[-c((n-4):(n+1))]+ SECOND[-c((n-4):(n+1))]+ THIRD[-c((n-4):(n+1))] + FOURTH[-c((n-4):(n+1))], Q=diag(NA,4),R=t(matrix(rep(diag(1,4),5),nrow=4))), H)
SSMregression(~ FIRST + SECOND + THIRD + FOURTH, Q=diag(1,4), H)

model <- SSModel(Y[(n-5):(n-1),1] ~ -1+ SSMregression(~ FIRST + SECOND + THIRD + FOURTH, Q=diag(1,4), H))
#R=t(matrix(rep(diag(1,4),5),nrow=5)))
```
```{r}


fit <- fitSSM(model, inits = c(0.1,0.1,0.1,0.1), method = "BFGS")

model <- fit$model
model$Q    # third coeffcient constant?
model$H    # reduced version of the QLIK
kal <- KFS(model,smoothing = "none",filtering=c("mean","state"))

```
```{r}
# the parameters for the 1 step prediction
plot.ts(kal$a[6:10] )  # third coefficient constant = 0?


```
```{r}
plot.ts(kal$a[3+4*(0:9)] ) # Seems to be useless for all lags. We should remove it to reduce the dimension of the space.
```
```{r}
# the parameters for the 1 step prediction
plot.ts(kal$a[,1:4] )
```
```{r}
# the variances estimation as mean square errors for 10 lags
sigma <- colMeans((kal$m-Y[(n-5):(n-1),1])^2,na.rm = TRUE)   # remove a burn-in period to estimate the variances
plot(sigma)

```
```{r}
# the predictions in sample
yhat<-ts(kal$m[,1],frequency = 4, start = c(1959,2))
ts.plot(yhat)

```
```{r}
# the estimation of the volatility, i.e. the condiitonal variance of the 1-step prediction

vol<-ts(kal$F[1,]-rep(1,n-10)+rep(sigma[1],n-10),frequency = 4, start = c(1959,2))
ts.plot(vol)
```
```{r}
kalman_frame <- data.frame(kal_unit <- as.vector(kal$a[,1]),
                           kal_hum <- as.vector(kal$a[,2]),
                           kal_wind <- as.vector(kal$a[,3]),
                           kal_temp <- as.vector(kal$a[,4]),
                           kal_count <- as.vector(kal$a[,5]),
                           time <- daily_data$Date[1:(n-1)])

# The parameters for the 1 step prediction
ggplot(data=kalman_frame, aes(x=Date, y=kal_unit)) + geom_line()
ggplot(data=kalman_frame, aes(x=Date, y=kal_hum)) + geom_line()
ggplot(data=kalman_frame, aes(x=Date, y=kal_wind)) + geom_line()
ggplot(data=kalman_frame, aes(x=Date, y=kal_temp)) + geom_line()
ggplot(data=kalman_frame, aes(x=Date, y=kal_count)) + geom_line()
```
```{r}
# intervals of predictions in sample
upperCI<-ts(yhat+2*sqrt(vol),frequency = 4, start = c(1959,2))
lowerCI<-ts(yhat-2*sqrt(vol),frequency = 4, start = c(1959,2))
ts.plot(ytraining,yhat,upperCI,lowerCI,col=1:4)
ts.plot(ts(cbind(ytraining[-(1:10)],yhat[-(1:10)],upperCI[-(1:10)],lowerCI[-(1:10)])),col=1:4)
# Prediction out of sample
ypred<-kal$m[n-10,]  # here we use different lags
volpred<-kal$F[,n-10]-rep(1,10)+sigma # here we use the variances for different lags
ts.plot(cbind(Y[(n-10):(n-1)],as.numeric(ypred),as.numeric(ypred+2*sqrt(volpred)),as.numeric(ypred-2*sqrt(volpred))),col=1:4)
```
